{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ba959c",
   "metadata": {},
   "source": [
    "###  11-1. 들어가며\n",
    "안녕하세요! 😊  \n",
    "\n",
    "'수식 없이도 이해할 수 있는 ChatGPT와 Stable Diffusion'을 학습하러 오신 여러분을 환영합니다!  \n",
    "\n",
    "ChatGPT와 Stable Diffusion, 들어보신 적이 있나요? 두 모델 모두 2022년부터 소개되었고, 그 이후 많은 사람들이 관심을 받은 인공지능 모델이에요.  \n",
    "\n",
    "ChatGPT는 텍스트를, Stable Diffusion은 이미지를 생성한다는 것은 이미 아실 거에요. 보통 텍스트를 다루면 자연어 처리(NLP), 이미지를 다루면 컴퓨터 비전(CV) 분야라고 하죠. 분야가 다른데, 왜 여기서는 두 모델을 동시에 다루는 것일까요?  \n",
    "\n",
    "ChatGPT와 Stable Diffusion의 공통점은 기존에 없던 무엇인가를 생성한다는 것이에요. 즉 이 두 모델은 생성형 AI/생성 AI(Generative AI) 의 대표적인 모델이라고 할 수 있어요. 생성형 AI는 이미지, 텍스트, 코드 등의 다양한 데이터를 사용하여 새로운 데이터를 생성하는 인공지능이에요.  \n",
    "\n",
    "시장 조사 기관인 Grandview Research에 의하면 생성형 AI 시장이 2030년까지 매년 34.4%씩 성장할 것이라고 해요.  \n",
    "\n",
    "그러니 지금부터라도 생성형 AI에 관심을 갖고 공부를 해야하지 않을까요?  \n",
    "\n",
    "이번 노드에서 우리는 영상을 통해 ChatGPT와 Stable Diffusion을 이해하고 실습을 통해 생성형 AI를 사용해 볼 거예요.  \n",
    "\n",
    "먼저 아이스브레이킹으로 이번 노드를 시작해 볼까요? 🏃‍♀️  \n",
    "\n",
    "\n",
    "#### 학습 내용\n",
    "1. 생성형 AI(Generative AI)의 시대 : 생성형 AI인 ChatGPT와 Stable Diffusion 모델이 무엇인지 알아보고, 직접 사용해 봅니다.\n",
    "2. ChatGPT와 Stable Diffusion은 어떻게 발전되어 왔을까요? ChatGPT와 Stable Diffusion의 원리를 알아봅니다.\n",
    "3. Generative AI가 바꿀 세상의 모습은? 생성형 AI가 바꿀 세상의 모습을 알아보고, 그에 대비하는 우리의 자세를 생각해 봅니다.\n",
    "4. Stable Diffusion 모델로 이미지 생성하기 : 허깅페이스를 사용하여 Stable Diffusion 모델로 원하는 이미지를 생성하는 실습을 합니다.\n",
    "\n",
    "#### 학습 목표\n",
    "- ChatGPT와 Stable Diffusion 모델을 사용할 수 있습니다.\n",
    "- ChatGPT와 Stable Diffusion의 원리를 설명할 수 있습니다.\n",
    "- Stable Diffusion 모델을 사용하여 이미지를 생성할 수 있습니다.\n",
    "\n",
    "### 11-2.생성형 AI(Generative AI)의 시대\n",
    "#### ChatGPT 사용해 보기\n",
    "ChatGPT는 OpenAI가 2022년 말에 발표한 대화형 언어모델인데요, 챗봇처럼 질문을 하면 AI가 바로 대답을 해주기 때문에 많은 사람들의 관심을 받고 있어요. 5일 동안 백만 명의 사용자가 ChatGPT를 사용했다고 하니 정말 놀랍지 않나요?\n",
    "\n",
    "\n",
    "#### Stable Diffusion 사용해 보기\n",
    "Stable Diffusion은 문장을 쓰면 이미지를 생성해주는 모델이에요. Stability AI에서 오픈소스로 모델을 배포하였죠. OpenAI의 DALL-E나 구글의 Imagen과 다르게 컴퓨터 리소스 사용량을 많이 줄였고, 코드도 공개되었기 때문에 Stable Diffusion을 사용한 다양한 오픈소스 프로젝트도 생기고 있어요. 당연히 우리도 무료로 사용할 수 있구요.  \n",
    "아직 Stable Diffusion을 사용해보지 않았다면 데모에 들어가서 이미지를 생성해 보세요.  \n",
    "- 데모 링크 : https://stablediffusionweb.com/#demo\n",
    "\n",
    "Stable Diffusion 역시 영어로 원하는 문장을 입력해야 해요. 영어에 익숙하지 않다면 Stable Diffusion Prompt Generator를 사용해 보세요. 간단한 단어만 입력하면 알아서 정교한 문장과 이미지를 생성해 줍니다.\n",
    "- 프롬프트 제너레이터 링크 : https://stablediffusionweb.com/ko/prompt-generator#demo\n",
    "\n",
    "### 11-3. ChatGPT와 Stable Diffusion은 어떻게 발전되어 왔을까요?\n",
    "#### 참고 자료\n",
    "영상에서 설명한 내용을 따로 깊이 공부해 보고 싶은 분들을 위해 몇 개의 링크를 공유합니다. 지금 당장 공부할 필요는 없지만 기억해 두었다가 언젠가 시간이 날 때 각 모델을 깊이 공부하신다면 여러분의 실력은 쑥쑥 성장해 있을 거예요! 🌳\n",
    "\n",
    "- Attention Mechanism이 처음 소개된 논문: Neural Machine Translation by Jointly Learning to Align and Translate(https://arxiv.org/abs/1409.0473)\n",
    "- Self-Attention 논문: Attention is All you need(https://arxiv.org/abs/1706.03762)\n",
    "- GPT3 논문: Language Models are Few-Shot Learners(https://arxiv.org/abs/2005.14165)\n",
    "- ImageGPT\n",
    "    - OpenAI의 ImageGPT 소개(https://openai.com/index/image-gpt/)\n",
    "    - 논문: Generative Pretraining from Pixels(https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)\n",
    "- DALL-E\n",
    "    - OpenAI의 DALL-E 소개(https://openai.com/index/dall-e/)\n",
    "    - 논문: Zero-Shot Text-to-Image Generation(https://arxiv.org/pdf/2102.12092)\n",
    "- DALL-E 2\n",
    "    - OpenAI의 DALL-E 2 소개(https://openai.com/index/dall-e-2/)\n",
    "    - 논문: Hierarchical Text-Conditional Image Generation with CLIP Latents(https://arxiv.org/abs/2204.06125)\n",
    "- Diffusion 모델 논문: Denoising diffusion probabilistic models(https://arxiv.org/abs/2006.11239)\n",
    "- Stable Diffusion 논문: High-Resolution Image Synthesis with Latent Diffusion Models(https://arxiv.org/abs/2112.10752)\n",
    "- OpenAI의 ChatGPT 소개(https://openai.com/index/chatgpt/)\n",
    "    - ChatGPT는 GPT3 기반으로 만들어진 모델이라 논문이 없습니다.\n",
    "- RLHF 관련 논문: Training language models to follow instructions with human feedback(https://arxiv.org/abs/2203.02155)\n",
    "\n",
    "### 11-4. 생성형 AI가 바꿀 세상의 모습은?\n",
    "\n",
    "### 11-5. ChatGPT를 사용하여 이미지 프롬프트 만들기\n",
    "'Garbage In, Garbage Out'이라는 말을 들어보셨나요? 좋은 입력이 있어야 좋은 출력이 있다는 뜻인데요, 다양한 맥락에서 사용될 수 있지만 AI에게도 해당됩니다.  \n",
    "\n",
    "보통 AI에게 좋은 질문을 해야 좋은 대답이 나온다고 알려져 있어요. 즉 우리는 AI와 대화하기 위해 AI와 대화하는 법을 배워야 합니다. 최근 들어 AI에게 좋은 질문을 하는 법이 활발히 연구되고 있고, 이를 프롬프트 엔지니어링(Prompt Engineering)이라고 부릅니다.  \n",
    "\n",
    "앞으로 우리는 Stable Diffusion을 사용하여 다양하게 이미지를 생성할 예정이기 때문에 이미지를 생성하는 프롬프트를 위주로 프롬프트를 작성하는 법을 배워볼 거에요. 먼저 기본적인 내용을 배우고, ChatGPT 확장 프로그램을 이용하여 ChatGPT에게 이미지 생성 프롬프트를 만들어 달라고 해보겠습니다. 😁  \n",
    "\n",
    "#### Stable Diffusion 프롬프트 엔지니어링\n",
    "먼저 Stable Diffusion 프롬프트 엔지니어링의 기본적인 내용부터 살펴봅시다. 이미지 생성 프롬프트 엔지니어링은 기본적으로 그림이나 사진에서 사용하는 기법이나 기술을 사용하고 있습니다.\n",
    "\n",
    "##### 기본 속성 입력\n",
    "가장 기본적으로 입력해야할 속성부터 알아볼까요? 각 목록에서 하나를 선택하여 프롬프트를 입력하면 원하는 이미지를 보다 쉽게 출력할 수 있다고 해요.    \n",
    "\n",
    "##### 사진/그림 등\n",
    "- 주제: 사람/동물/풍경/사물 등\n",
    "- 빛: 부드럽게/네온 사인/자연광 등\n",
    "- 주변 환경: 야외/실내/우주/수중 등\n",
    "- 색: 파스텔톤/어둡게/강렬하게 등\n",
    "- 시점: 앞/뒤/옆/위 등\n",
    "- 스타일: 3D/지브리풍/영화 등\n",
    "\n",
    "'''\n",
    "a photo of a ugly golden retriever \n",
    "wearing a swimsuit, \n",
    "natural light under the water, \n",
    "with dark colors, by Studio Ghibli\n",
    "'''\n",
    "##### 하이퍼파라미터\n",
    "Stable Diffusion에서 변경할 수 있는 하이퍼파라미터가 있습니다.  \n",
    "\n",
    "- 해상도: 기본값은 512 x 512입니다.\n",
    "- CFG(Classifier Free Guidance): 작은 수일수록 모델에게 자유도를 준다고 합니다. 기본값은 7입니다.\n",
    "- Step count: 디노이징(denoising, 노이즈를 제거해주는 기법) 스텝의 수를 조절할 수 있습니다. 수가 클수록 좋다고 하지만 초보들은 기본값인 50을 사용하는 것이 좋습니다.\n",
    "- seed: seed를 사용하면 동일한 프롬프트를 넣었을 때 동일한 결과를 얻을 수 있습니다. 기본값은 random입니다.\n",
    "- sampler: 생성되는 이미지를 디노이즈할 때 사용되는 파라미터입니다. 초보자들은 DDIM을 사용하는 것이 좋은데, 그 이유는 10 스텝만으로도 좋은 이미지가 빠르게 생성되기 때문이라고 합니다.\n",
    "위에서 소개한 방법을 이용하여 다양한 프롬프트를 만들어 멋진 이미지를 생성해 보세요!\n",
    "\n",
    "Stable Diffusion 프롬프트 엔지니어링을 더 알고 싶다면 아래의 자료를 참고해 보세요. 참고 자료일 뿐이므로 반드시 공부할 필요는 없어요.\n",
    "- https://openart.ai/promptbook\n",
    "- https://lexica.art/\n",
    "\n",
    "#### ChatGPT를 이용하여 이미지 생성 프롬프트 만들기\n",
    "직접 이미지 생성 프롬프트를 만드는 것은 어려울 수 있습니다. 우리는 영어가 모국어가 아니고, 그림이나 사진에 대해 잘 알지 못하기 때문이죠. 😓  \n",
    "\n",
    "그렇기 때문에 우리는 ChatGPT에게 이미지 생성 프롬프트를 만들어달라고 할 거에요. 하지만 ChatGPT를 사용하기 위해서는 또다시 프롬프트를 제대로 작성해야 하죠. 우리는 프롬프트의 굴레에서 벗어날 수 없는 것일까요?  \n",
    "\n",
    "하늘이 무너져도 솟아날 구멍이 있다는 속담이 있듯, 우리에게는 ChatGPT 확장 프로그램이 있습니다! 지금부터 확장 프로그램을 사용하여 ChatGPT에게 Stable Diffusion 사용을 위한 이미지 생성 프롬프트를 요청해 보도록 해요. 😄  \n",
    "\n",
    "##### AIPRM for ChatGPT 설치 및 계정 연동하기\n",
    "크롬 확장 프로그램인 AIPRM for ChatGPT를 설치하고, ChatGPT로 들어갑니다. 그러면 아래와 같이 AIPRM for ChatGPT와 ChatGPT를 연결하겠냐는 메시지가 나옵니다. Continue를 눌러주세요.    \n",
    "- https://chromewebstore.google.com/detail/aiprm-for-chatgpt/ojnbohmppadfgpejeebfnmnknjdlckgj\n",
    "\n",
    "\n",
    "다음 창이 나오면 I have read and agree to the terms of use for AIPRM and Privacy policy에 체크하고, Connect with Google account를 클릭합니다.  \n",
    "\n",
    "구글 계정을 선택하고, 엑세스를 허가한 후 이메일로 승인까지 하면 확장 프로그램을 바로 사용할 수 있어요.  \n",
    "\n",
    "##### AIPRM for ChatGPT 사용하기\n",
    "모든 준비가 끝났으면 ChatGPT가 아래와 같은 화면으로 바뀝니다.  \n",
    "\n",
    "원하는 이미지 프롬프트를 얻기 위해 몇 가지 세팅이 필요합니다. 아래와 같이 조건을 설정해 보세요.  \n",
    "\n",
    "- Topic: Generative AI\n",
    "- Activity: Stable Diffusion\n",
    "- Sort by: Top Votes(원하는 것을 선택해 주세요)\n",
    "전세계 사람들이 만들어 둔 프롬프트 엔지니어링 가이드 중 하나를 선택하고, 이미지의 키워드를 적어보세요.  \n",
    "\n",
    "- Output in: English로 선택해 주세요.\n",
    "- Tone: 업그레이드된 프로그램을 선택해야 다양한 설정값을 사용할 수 있습니다.\n",
    "- Writing Style: 업그레이드된 프로그램을 선택해야 다양한 설정값을 사용할 수 있습니다.\n",
    "\n",
    "'''\n",
    "((Best quality)), ((masterpiece)), ((realistic)), \"Castle in the Sky\" on eye level, scenic, masterpiece.\n",
    "\n",
    "Subject: Castle\n",
    "Action: Floating\n",
    "Context: Fantasy world\n",
    "Environment: In the clouds\n",
    "Lighting: Bright, sunbeams\n",
    "Artist: John Howe\n",
    "Style: Realism\n",
    "Medium: Oil on canvas\n",
    "Type: Landscape\n",
    "Color Scheme: Pastel\n",
    "Computer graphics: Cycles\n",
    "Quality: 8K\n",
    "\n",
    "Positive Prompt:\n",
    "A magnificent castle floats gracefully in the clouds, basking in the warm glow of the sunbeams. Its grandeur and majesty are accentuated by the pastel hues of the sky, making it seem like a scene straight out of a fairy tale. The realistic detailing in the oil painting captures every intricate feature of the castle, giving it a lifelike quality. John Howe's masterful use of realism and the subtle play of light and shadow create a breathtaking landscape that transports the viewer to a magical world.\n",
    "\n",
    "Negative Prompts:\n",
    "Cropped image, out of frame, grainy, low-res, blurry, bad anatomy, poorly drawn, bad art\n",
    "여러분들이 생성한 이미지 프롬프트는 어떤 것인가요?\n",
    "\n",
    "'''\n",
    "\n",
    "이제부터 Stable Diffusion을 사용하여 이미지를 생성하는 실습과 프로젝트를 할텐데요, 대부분 프롬프트를 작성해야 합니다. 그 때마다 직접 프롬프트를 작성하는 것도 좋지만 AIPRM for ChatGPT를 사용하면 더 멋진 이미지를 생성할 수 있습니다.\n",
    "\n",
    "### 11-6. Stable Diffusion 모델로 이미지 생성하기\n",
    "지금까지 chatGPT와 Stable Diffusion 모델을 알아보았습니다. 모델을 배웠다면 실습을 해봐야겠죠? 🤗  \n",
    "\n",
    "Stable Diffusion 모델을 이용하여 이미지를 생성하는 쉬운 방법 중 하나는 허깅페이스(Hugging Face)를 이용하는 것입니다.  \n",
    "\n",
    "허깅페이스(Hugging Face)  \n",
    "- 트랜스포머(Transformer) 기반으로 하는 머신러닝 및 인공지능 모델과 데이터 셋을 제공하는 세계 최대 플랫폼이자 커뮤니티입니다. 모델을 사용하려면 직접 모델을 구현하고 훈련시켜 레이어와 모델을 선언해야 하지만 허깅페이스를 이용하면 간단한 코드만으로 모델을 사용할 수 있습니다. 뿐만 아니라 사용자들이 직접 구현한 모델이나 수집한 데이터셋을 공유하고 토론하는 커뮤니티 공간이 활발하게 운영되고 있습니다.\n",
    "\n",
    "우리는 허깅페이스에서 제공하는 Stable Diffusion 모델 중 Diffusers를 사용할 예정입니다. Diffusers는 이미지, 오디오, 3D 분자 구조를 생성하는 모델로, 파이프라인(Autoencoder, Conditional Unet, CLIP text encoder 등), 스케쥴러(속도와 결과물의 품질 조정), 사전학습된 모델로 구성되어 있습니다.  \n",
    "\n",
    "허깅페이스에서 제공하는 코드를 참고하였습니다. 아래의 코드에서는 파이토치를 사용하지만 파이토치를 배우지 않았더라도 코드를 천천히 살펴보면 쉽게 이해할 수 있을 거에요.  \n",
    "\n",
    "#### 모델 준비하기\n",
    "먼저 Diffusers를 설치합니다. 아래와 같은 에러 메시지가 나오지만 무시하셔도 괜찮습니다.  \n",
    "'''\n",
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "datasets 1.14.0 requires huggingface-hub<0.1.0,>=0.0.19, but you have huggingface-hub 0.13.3 which is incompatible.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -qq git+https://github.com/huggingface/diffusers.git transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819dfb4",
   "metadata": {},
   "source": [
    "#### Text-to-Image Generation\n",
    "Stable Diffusion의 가장 기본적인 기능은 텍스트를 입력하면 이미지를 생성하는 Text-to-Image Generation입니다. 먼저 Text-to-Image Generation 파이프라인을 불러옵시다. 다운로드를 받을 때까지 1-2분 정도 걸리니 기다려주세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5809dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 113\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.88.0.1'), PosixPath('443'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.88.9.209'), PosixPath('8888'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.88.9.209'), PosixPath('8887'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import diffusers.pipelines.pipeline_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDiffusionPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPushToHubMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     r\"\"\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mDiffusionPipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'compiler'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/1720743807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiffusionPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDPMSolverMultistepScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/diffusers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    856\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import diffusers.pipelines.pipeline_utils because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'compiler'"
     ]
    }
   ],
   "source": [
    "# 오류발생, 코랩에서 하기(11_2파일 참고)\n",
    "import torch \n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# 파이프라인 불러오기\n",
    "repo_id = \"stabilityai/stable-diffusion-2-base\"\n",
    "pipe = DiffusionPipeline.from_pretrained(repo_id, torch_dtype=torch.float16)\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2c720",
   "metadata": {},
   "source": [
    "#### 하나의 이미지 생성하기\n",
    "파이프라인이 준비되었다면 이제부터는 정말 쉽습니다. 원하는 이미지를 생성하기 위한 프롬프트(prompt)만 잘 입력해주면 되니까요!\n",
    "\n",
    "여러분들이 원하는 이미지를 영어로 입력해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6578a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: A photo of a Korean man in his 30s who is experiencing AI for the first time being surprised by an AI robot \n"
     ]
    }
   ],
   "source": [
    "prompt = str(input('prompt: '))  # 프롬프트를 영어로 입력해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87e5b4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/2066186898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 입력한 프롬프트를 사용하여 이미지 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 이미지 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# 이미지 저장 폴더 만들기   \n",
    "import os\n",
    "os.mkdir(\"/aiffel/aiffel/diffusers\")    # diffusers 폴더를 이미 만들었다면 주석 처리해 주세요.\n",
    "\n",
    "# 입력한 프롬프트를 사용하여 이미지 생성 \n",
    "image = pipe(prompt, num_inference_steps=25).images[0]\n",
    "\n",
    "# 이미지 저장\n",
    "image.save(\"/aiffel/aiffel/diffusers/image.png\")  \n",
    "\n",
    "# 이미지 출력 \n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e5158",
   "metadata": {},
   "source": [
    "아래의 하이퍼파라미터를 변화시키면 더 멋진 이미지가 나올 수 있습니다.\n",
    "\n",
    "- height, width: 생성될 이미지의 가로와 세로 픽셀 크기를 조절할 수 있습니다. 8의 배수로 설정해 주세요.\n",
    "- num_inference_steps: denoising 스텝 수로, 값이 커질수록 고해상도 이미지가 출력되지만 출력되는 시간이 오래 걸립니다. default 값은 50입니다.\n",
    "- guidance_scale: 얼마나 주어진 프롬프트에 근접한 이미지를 생성할지를 설정하는 하이퍼파라미터로, 값이 커질수록 문자열에 근접한 이미지가 생성되지만 이미지 품질이 떨어질 수 있습니다. default는 7.5입니다.\n",
    "\n",
    "#### 여러 개의 이미지 생성하기\n",
    "이번에는 하나의 프롬프트로 여러 개의 이미지를 생성해 봅시다.\n",
    "\n",
    "이미지 처리를 해주는 파이썬 라이브러리인 pillow를 사용하여 여러 개의 이미지를 담을 틀을 먼저 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acb7f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 이미지 처리 라이브러리 pillow 불러오기 \n",
    "from PIL import Image  \n",
    "\n",
    "# 틀 만들기\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows * cols\n",
    "\n",
    "    w, h = imgs[0].size  \n",
    "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box = (i%cols * w, i // cols * h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8f1d1",
   "metadata": {},
   "source": [
    "틀을 만들어 주었으니 원하는 이미지를 출력해 볼까요?  \n",
    "\n",
    "출력하고 싶은 이미지의 개수를 적어주고, 프롬프트를 리스트 안에 적어주세요. 아래의 코드에서는 1개의 프롬프트만 사용했지만 여러 개의 프롬프트를 사용할 수도 있어요.  \n",
    "\n",
    "주의할 점은 이미지의 개수는 이미지를 담을 틀의 개수와 동일해야 한다는 것이에요. assert len(imgs) == rows * cols라는 코드에서 볼 수 있듯이, 출력하고 싶은 이미지의 개수가 6개라면 행과 열은 2와 3으로 설정해 주어야 해요. 3과 2, 1과 6도 가능하겠죠?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09583a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/3429080086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 이미지 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 이미지 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# 이미지의 개수 \n",
    "num_images = 6\n",
    "\n",
    "# 프롬프트 입력\n",
    "prompt = ['a horse riding a person'] * num_images\n",
    "\n",
    "# 이미지 생성\n",
    "images = pipe(prompt).images\n",
    "\n",
    "# 이미지 출력\n",
    "grid = image_grid(images, rows= 3, cols= 2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efeb3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 메모리를 지우는 코드입니다. \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5e153",
   "metadata": {},
   "source": [
    "#### Image-to-Image Generation\n",
    "- Image-to-Image Generation은 프롬프트뿐 아니라 이미지를 입력으로 넣으면 다른 이미지로 변형시켜 주는 기능입니다. 앞의 영상에서 언급되었던 'AI야 우리 딸 아이 그림 좀 손봐줘'가 이 기능을 사용한 것이죠.\n",
    "\n",
    "- Diffusers에는 이 기능이 포함된 파이프라인을 이미 만들어 두었기 때문에 파이프라인을 불러오기만 하면 쉽게 모델을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97381e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-to-Image Generation 파이프라인 불러오기    \n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "\n",
    "device = \"cuda\"\n",
    "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859d41e",
   "metadata": {},
   "source": [
    "#### 하나의 이미지 생성하기\n",
    "사용할 이미지를 불러옵시다.  \n",
    "\n",
    "이미지를 클라우드에 올려서 사용해도 되고, 아래의 코드와 같이 인터넷에 있는 이미지를 가져와도 좋습니다. 여기서는 허깅페이스에서 제공하는 기본 이미지를 사용해 볼게요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd49ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
    "\n",
    "# url 호출하기\n",
    "response = requests.get(url)\n",
    "\n",
    "# 이미지 열기\n",
    "init_img = Image.open(BytesIO(response.content)).convert(\"RGB\")  # 이미지를 메모리로 읽어와서 RGB로 변경합니다. \n",
    "init_img = init_img.resize((768, 512))  # 이미지의 크기를 조절합니다. \n",
    "init_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_img = Image.open(\"/aiffel/aiffel/diffusers/image.png\", mode = 'r')\n",
    "# init_img = init_img.resize((768, 512)) \n",
    "# init_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ea550",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A fantasy landscape, trending on artstation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc43139",
   "metadata": {},
   "source": [
    "이미지를 생성하고 저장해 보겠습니다. 아래의 코드에는 조절할 수 있는 하이퍼파라미터가 있습니다.\n",
    "\n",
    "- seed: 동일한 입력 문장과 각종 설정을 넣었을 때 동일한 시드 값을 주면 같은 이미지를 생성할 수 있습니다.\n",
    "- strength: 레퍼런스 이미지에서 얼마나 변형할지를 설정하는 하이퍼파라미터로, 값이 커질수록 원본 이미지와 다른 이미지를 생성합니다. 0과 1 사이의 값을 선택할 수 있으며, default는 0.8입니다.\n",
    "- guidance_scale: 얼마나 주어진 프롬프트에 근접한 이미지를 생성할지를 설정하는 하이퍼파라미터로, 값이 커질수록 문자열에 근접한 이미지가 생성되지만 이미지 품질이 떨어질 수 있습니다. default는 7.5입니다.\n",
    "- num_inference_steps: denoising 스텝 수로, 값이 커질수록 고해상도 이미지가 출력되지만 출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a697936e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/2665209780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 모델을 사용할 때마다 동일한 이미지를 생성하기 위해 seed를 설정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/aiffel/aiffel/diffusers/fantasy_landscape.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "generator = torch.Generator(device=device).manual_seed(1024)   # 모델을 사용할 때마다 동일한 이미지를 생성하기 위해 seed를 설정합니다.  \n",
    "\n",
    "images = pipe(prompt=prompt, image=init_img, strength=0.75, guidance_scale=7.5).images\n",
    "images[0].save(\"/aiffel/aiffel/diffusers/fantasy_landscape.png\")\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61468f",
   "metadata": {},
   "source": [
    "#### 여러 개의 이미지 생성하기\n",
    "여러 개의 프롬프트를 사용하여 여러 장의 이미지를 한번에 생성할 수도 있습니다. Text-to-Image Generation에서 사용했던 코드를 사용하였으니 코드를 자유롭게 변경해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea497fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/3231891408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 이미지 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "num_images = 2\n",
    "\n",
    "# 프롬프트 입력\n",
    "prompt = ['A fantasy landscape, trending on artstation'] * num_images\n",
    "\n",
    "# 이미지 생성\n",
    "generator = torch.Generator(device=device).manual_seed(1024)\n",
    "images = pipe(prompt=prompt, image=init_img, strength=0.9, guidance_scale=13.5, num_inference_steps=50, generator=generator).images\n",
    "images\n",
    "\n",
    "# 이미지 출력\n",
    "grid = image_grid(images, rows=1, cols=2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e1ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 이미지를 생성해 보세요. \n",
    "# [[YOUR CODE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0492f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
