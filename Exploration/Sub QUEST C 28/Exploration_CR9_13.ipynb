{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93bce1e",
   "metadata": {},
   "source": [
    "### 13-2. 실험실 속 머신러닝 모델\n",
    "MLOps 세상에 온 여러분들 환영합니다!! MLOps는 지금까지 여러분들이 배웠던 인공지능 모델링과 색다른 주제입니다.\n",
    "\n",
    "MLOps를 배우기 전에 우선 MLOps가 무엇이며 어떤 이유에서 나오게 되었으며 주요 Tool들을 배울 예정입니다.\n",
    "\n",
    "#### MLOps가 무엇일까요?\n",
    "MLOps는 머신러닝(ML)과 Operations(Ops)가 합쳐진 체계를 의미합니다. 기존 머신러닝 특히 딥러닝 파트는 연구 단계에서 많은 발전을 이루었습니다. 이러한 모델들을 실제 서비스에 도입하려고 할 때 소프트웨어적인 문제들이 발생하기 시작했습니다. 그 중 구글은 2015년에 \"Hidden Technical Debt in Machine Learning Systems\"라는 논문을 발표해 실제 머신러닝 시스템에 숨겨져 있는 소프트웨어적인 기술부채에 대해 언급했습니다.\n",
    "- https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf\n",
    "\n",
    "해당 논문에서 머신러닝 시스템을 개발하고 배포하는 것은 비교적 빠르고 비용이 덜 들지만 머신러닝 시스템을 유지하는 것은 어렵고 비용이 많이 들어간다고 이야기합니다. 또한 시스템 유지에 들어가는 기술 부채들은 코드 리팩토링과 같은 코드 수준에서의 부채가 아닌 시스템적인 수준에서 작동하기 때문에 감지되기도 어렵습니다. 해당 문제를 하나씩 살펴보도록 하겠습니다.  \n",
    "\n",
    "#### 머신러닝과 소프트웨어 개발 방식의 차이(Complex Models Erode Boundaries)\n",
    "\n",
    "기존에 소프트웨어 개발에서는 캡슐화하고 모듈식으로 설계를 합니다. 모듈로 정리하게 된다면 코드 수준에서 개선이 용이하며 유지관리를 가능하게 만듭니다. 이걸 쉽게 이야기하면 데이터베이스를 정리하는 코드모듈이 따로 있고 웹페이지를 만드는 코드 모듈이 있다고 생각하시면 됩니다. 머신러닝은 어떨까요? 머신러닝은 데이터에 따라서 소프트웨어 로직이 달라지기 때문에 깔끔한 모듈화가 불가능합니다. 예를 들어서 우리가 모델을 학습한다고 진행했을 때 실험을 진행할 때는 Random number를 고정하는 방식을 사용했습니다. 현실 세계의 경우에 추가 학습을 진행하면 파라미터, 학습 설정, 샘플링 방식, 수렴 임계값과 같은 모든 내용이 바뀌게 됩니다. 그렇기에 소프트웨어 프로그래밍 형식으로 머신러닝에 대입하는 건 상당히 어렵습니다.  \n",
    "\n",
    "#### 데이터 디펜더시(Data Dependencies Cost More than Code Dependencies)\n",
    "\n",
    "소프트웨어 엔지니어링 환경에서 디펜더시는 코드가 복잡하거나 기술 부채가 쌓여서 생기는 문제였습니다. 예를 들어 다른 엔지니어가 짠 코드가 복잡해서 다른 엔지니어가 건들 수 없고 건드리게 되면 서비스가 마비되는 상황이 있을 수 있습니다. 머신러닝에서의 디펜더시는 코드 수준에서 일어나는 디펜더시도 있지만 데이터 기반으로 일어나는 디펜더시가 더 큰 문제입니다. 머신러닝에서의 코드 디펜더시는 컴파일러로 해결가능하지만 데이터 디펜더시는 기술 부채 쌓는건 비슷하지만 찾는 것부터 어렵습니다. 데이터 디펜더시가 생긴 이유는 몇몇 입력 데이터에서 변환된 신호가 학습을 할때마다 변화할 수 있기 때문입니다. 만일 이러한 입력 신호를 고정되게끔 바꿔버린다고 하면 다른 데이터에 영향을 줄 수 있습니다. 또한 데이터중에서 실제로 그다지 의미가 없는 데이터라 하더라도 마찬가지로 수정을 하면 머신러닝 시스템에 문제를 발생시킬 수 있습니다. 결국 머신러닝 시스템은 데이터에 영향을 받을 수 밖에 없는 시스템이기 때문에 데이터를 수정한다면 머신러닝 전체 시스템에 문제가 발생합니다.  \n",
    "\n",
    "#### 피드백 순환루프(Feedback Loops)\n",
    "\n",
    "실험실에서의 머신러닝은 고정된 벤치마크 데이터셋을 이용해서 실험합니다. 그러나 현실에서의 머신러닝은 데이터셋이 고정되어 있지 않습니다. 추천시스템으로 예를 들어 설명하면 여름 데이터셋을 이용해서 만든 머신러닝 모델은 여름에는 잘 작동하지만 계절이 변할 때 정확도가 점점 떨어지게 됩니다. 이를 위해 머신러닝 시스템은 피드백 순환루프를 만들어야 합니다. 더 큰 문제는 한 모델이 여러가지를 수행하는데 피드백을 받아 수정할때 다른 곳에도 영향을 미치는 것입니다. 이런 경우 모델이 문제가 발생하는 것을 알면서도 빠르게 모델 수정을 할 수 없게 되면서 시스템을 마비시킬 수 있습니다.  \n",
    "\n",
    "#### 머신러닝의 안티 패턴들(ML-System Anti-Patterns)\n",
    "\n",
    "실험실에서의 머신러닝은 추론과 학습이 실험의 대부분을 차지하지만 실제 머신러닝 시스템에서는 데이터 수집부터 모니터링까지 다양한 영역을 커버하고 있습니다. 그렇다보니 머신러닝 시스템에서 접착 코드가 남발하게 되어 이는 효율성에서 매우 떨어집니다. 또한 실험된 모델을 현실에 급하게 적용하다보면 파이프라인을 복잡하게 설계되면 추후에 문제가 발생할 때 처리하기 어려워집니다.  \n",
    "\n",
    "파이프라인이 꼬이고 접착 코드가 남발하면 개별 branch들을 많이 만들어서 실험하게 되고 branch가 많아지게 되면 이전 버전의 호환성 이슈로 비용을 크게 증가시킬 수 있습니다. 그밖에도 데이터가 어떤 타입으로 인코딩 되어있는지, 다양한 라이브러리를 사용해서 만드는 것은 추후 개선작업을 어렵게 만듭니다. 마지막으로 프로토타입을 만드는 것은 좋지만 프로토타입이 현실 세계와 동일하게 작동한다는 착각을 해서는 안됩니다.  \n",
    "\n",
    "#### 설정 부채(Configuration Debt)\n",
    "\n",
    "머신러닝은 다른 시스템과 달리 하이퍼 파라미터 설정이 필수적입니다. 이러한 설정값은 해당 feature를 사용하는지, 데이터를 어떤 방식으로 선택하고 사용하는지, 전처리 결과등을 설정합니다. 설정값들은 머신러닝 시스템에서 많은 영향을 끼치지만 실제 연구를 진행할 때 해당 설정값에 대한 검증이나 테스트를 진행하지 않는 경향이 있습니다.  \n",
    "\n",
    "#### 현실에서 발생하는 변화들(Dealing with Changes in the External World)\n",
    "\n",
    "앞서 설명한 것처럼 통제된 환경에서 만들어진 머신러닝과 현실세계의 머신러닝 시스템은 차이가 있습니다. 즉 외부 환경으로 인한 유지보수가 지속적으로 발생하고 특정 수치를 조정해야 할 때가 있으며 모니터링과 테스팅을 지속적으로 진행해줘야 합니다. 이를 해결하기 위해서는 자동으로 변화에 따라 대응하는 시스템을 만들어야 합니다.  \n",
    "\n",
    "위에 있는 내용을 정리하면 통제된 환경에서 만들어진 머신러닝은 실제 시스템에 적용했을 때 부채가 발생하며 이를 해결해나가야 한다로 정의할 수 있습니다.  \n",
    "\n",
    "어떤가요?  \n",
    "\n",
    "해당 내용들을 읽었을 때 많이 와닿으셨나요? 몇몇 분들은 공감하실 수 있겠지만... 몇몇 분들은 잘 와닿지 않았을거라 생각합니다.  \n",
    "\n",
    "그.래.서. 준비했습니다!!\n",
    "\n",
    "모두의연구소에서 매년 진행하고 있는 컨퍼런스인 MODUCON 영상중에서 2019년에 윤성국님께서 화성에서 온 ML모델러, 금성에서 온 ML 엔지니어 협업하기에 대한 이야기로 발표하셨습니다. 영상 보고 오겠습니다!  \n",
    "\n",
    "#### 화성에서 온 ML모델러, 금성에서 온 ML엔지니어 협업하기 - 윤성국\n",
    "- https://youtu.be/HDYkDQ9HWYg\n",
    "\n",
    "-----\n",
    "\n",
    "### 13-3. MLOps의 정의와 ML 시스템의 구성요소\n",
    "우리는 이전 스텝에서 실험실에서의 머신러닝 모델이 현실과 괴리감이 있다는걸 알았을거라 생각합니다. 이전 성국님 영상에서 ML 엔지니어와 ML 모델러(ML 리서쳐)가 협업이 필요하며 둘의 생각이 사뭇 다르다는것도 알게 되었다고 생각합니다. 그러면 이러한 괴리감을 해결하기 위해서 AI를 활용하는 기업들은 어떻게 해결했을까요?\n",
    "\n",
    "이때 등장한 개념이 바로 MLOps입니다. MLOps가 어떤 개념인지 먼저 살펴보고 가도록 하겠습니다. MLOps를 설명하는데 가장 좋은 영상으로 마이크로소프트에서 만든 애저 듣보잡 MLOps 101 1편을 보도록 하겠습니다.\n",
    "- https://www.youtube.com/watch?v=q2N6NZKxipg\n",
    "\n",
    "#### 머신러닝 시스템의 구성요소\n",
    "MLOps에서의 지속적인 통합, 지속적입 배포, 지속적인 학습을 이해하기 위해서는 우선적으로 머신러닝의 구성요소를 알아야 합니다. 이전 스텝에서 보았던 구글에서 나온 논문 \"Hidden Technical Debt in Machine Learning System\"에 머신러닝 시스템의 구성요소가 그림으로 나타냈습니다.\n",
    "\n",
    "content img\n",
    "[[출처 : Hidden Technical Debt in Machine Learning Systems]]\n",
    "머신러닝 시스템을 구성하는 도구는 춘추전국시대라 불릴만큼 각 요소마다 다양합니다. 이번 스텝에서는 각 항목이 어떤걸 의미하는지 알아보고 각 항목에서 자주 사용하고 있는 도구를 알아보도록 하겠습니다.\n",
    "\n",
    "#### 설정(Configuration)\n",
    "\n",
    "머신러닝에서 설정은 learning rate이나 weight decay와 같은 하이퍼파라미터 뿐만 아니라 데이터를 모을 때 어떤 방식으로 모아야 하고 ML 모델을 설계할 때 사용할 프레임워크, 서빙할 때 진행하는 방식과 같은 머신러닝 시스템에 전반적인 기획 내용을 포괄하고 있습니다. 해당 설정이 완료되어야 머신러닝 시스템을 설계할 때 방향성이 흔들리지 않습니다.\n",
    "\n",
    "#### 데이터 수집 (Data Collection)\n",
    "\n",
    "머신러닝 시스템에서의 데이터 수집은 가장 중요한 스텝입니다. AlexNet부터 현재 최신 모델들까지 전부 데이터의 중요성을 이야기하고 있습니다. 2023년 초를 강타한 GPT-4도 높은 수준의 데이터뿐만 아니라 다양한 데이터를 사용하고 있습니다. 그렇기에 좋은 데이터 수집은 좋은 모델이 나오게 하는 원동력으로 작용합니다.\n",
    "\n",
    "#### 특성 추출(Feature Extraction)\n",
    "\n",
    "데이터 수집이 완료되었으면 해당 데이터에 대한 특성을 추출하는 작업이 필요합니다. 데이터에서 특성을 추출해서 데이터에 유용한 정보를 얻으면 우리가 갖고 있는 데이터에 대한 이해도가 높아지게 됩니다. 이를 기반으로 우리는 머신러닝 시스템에서 분석 도구나 머신러닝 모델을 만들 때 사용하게 됩니다.\n",
    "\n",
    "#### 데이터 검증 (Data Verification)\n",
    "\n",
    "데이터를 수집할 때도 품질확인하는 것도 중요하지만 다시 한번 검증과정을 거쳐 실제 데이터가 정확하고 사용가능한지를 확인해야 한다. 데이터 검증(Data Verification)은 데이터 확인(Data Validation)과 목적에 있어서 차이를 보입니다. 데이터 검증(Data Verfication)은 데이터를 수집할 때 해당 데이터를 넣으면 정확도가 올라가고 지속적이라는걸 보장하기 위해서 데이터를 체크합니다. 반면에 데이터 확인(Data Validation)은 데이터가 모델에서 허용하는 범위에 있는지를 확인하는 작업입니다. 그렇기에 머신러닝 시스템은 고품질의 데이터를 지속적으로 모으고 해당 데이터로 모델 성능이 올라가는 것에 목적이 있기에 데이터 검증이 필수적입니다.\n",
    "\n",
    "#### 분석 도구 (Analysis Tools)\n",
    "\n",
    "머신러닝 모델을 만들었다면 머신러닝 모델이 잘 만들어졌는지 확인하는 분석 도구가 필요합니다. 물론 머신러닝을 만들 때 손실(loss)값이나 정확도(accuracy)로도 분석가능하지만 모델을 여러번 돌리는 실험에서는 해당 내용을 하나의 대시보드로 보고 확인하는 작업이 필요합니다. 뿐만 아니라 하이퍼 파라미터를 튜닝이 필요할 때도 해당 분석도구로 보여주는 대시보드는 큰 힘을 갖게 됩니다. 해당 분석도구의 대표적인 사례로 TensorBoard, W&B, mlflow 등이 있습니다.\n",
    "\n",
    "#### 프로세스 관리 툴(Process Management Tools)\n",
    "\n",
    "머신러닝 시스템이 자연스럽게 흘러가는걸 확인하려면 데이터의 흐름에 따라 시스템이 잘 운영되는지를 확인해야 합니다. 프로세스 관리 툴은 우리가 만든 시스템에 이상유무를 판단하는 툴입니다. 해당 툴의 대표적인 사례로 airflow, TFX, Kubeflow가 있습니다. 3가지 툴 모두 워크플로우를 구성할 수 있으며 스케줄링과 모니터링 기능까지 갖춰져있습니다. 실제 3가지 툴 모두 많은 기업들이 사용하고 있으며 각 회사의 도입기가 블로그로 작성되어 있습니다.\n",
    "\n",
    "마켓컬리의 Kubeflow 도입기\n",
    "- https://helloworld.kurly.com/blog/second-mlops/\n",
    "오늘의집의 Airflow 도입기\n",
    "- https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/\n",
    "스캐터랩의 TFX 도입기\n",
    "- https://tech.scatterlab.co.kr/use-tfx-pipeline-with-customization/\n",
    "\n",
    "#### 리소스 관리 (Machine Resource Management)\n",
    "\n",
    "머신러닝 시스템에서 모델을 학습할 때 필요한 GPU와 같은 리소스 관리가 필요합니다. 특히 GPU를 2대 이상 사용할 경우에는 분산학습을 진행해야 하기 때문에 리소스 관리 툴이 필요합니다. 만일 클라우드 GPU를 사용할 경우에 관리를 제대로 하지 않을 경우 비용이 과다하게 나오기 때문에 특별한 관리가 필요합니다. 해당 리소스 관리의 경우 쿠버네티스와 같은 오케스트레이션 툴뿐만 아니라 TerraForm과 같은 코드로 인프라를 관리하는 툴도 있습니다.\n",
    "\n",
    "#### 인프라 배포 (Serving Infrastructure)\n",
    "\n",
    "머신러닝을 실제 서비스로 진행하기 위해서는 머신러닝 모델을 배포하는 것 또한 중요합니다. 머신러닝 모델을 실제 배포하는 방법에는 모델 예측 결과를 Database에 저장하여 사용하는 방식이 있거나 API를 사용하는 방식이 있습니다. BentoML과 Gradio가 대표적인 인프라 배포 툴로 유명합니다.\n",
    "\n",
    "#### 모니터링(Monitoring)\n",
    "\n",
    "마지막으로 모델을 모니터링하면서 해당 모델이 추가적으로 학습이 필요한 상황인지 분석합니다. 모니터링을 진행하면서 새로 학습을 진행할 경우에는 기존에 로그로 쌓아놓았던 데이터를 사용할지 혹은 아예 새로운 데이터로 만들지를 결정하는 단계입니다. 모니터링의 경우 Google Cloud에서 사용하고 있는 VertexAI가 대표적인 서비스입니다.\n",
    "\n",
    "MLOps에 대한 정의와 머신러닝에 대한 구성요소와 대표적인 툴들을 정리하면서 설명했습니다. 근데 실제로 그럴까요? 2023년 3월에 마키나락스가 모두의연구소에서 글로벌 MLOps 트렌드와 한국형 MLOps 전략에 대해 강연을 진행했습니다.\n",
    "\n",
    "한번 보고 오시죠!!\n",
    "- https://www.youtube.com/watch?v=DRIEKB9smBY\n",
    "\n",
    "-----\n",
    "\n",
    "### 13-4. TFX (TensorFlow Extended) 소개하기\n",
    "우리가 MLOps를 하기 위해서 사용할 오픈소스 플랫폼은 바로 TFX(TensorFlow Extended)입니다. TFX는 고성능 머신러닝 작업을 위해 설계된 머신러닝 파이프라인 오픈소스 플랫폼로 다양한 Component들이 TFX로 빌드가능하며 개별적으로도 사용할 수 있습니다. 사실 MLOps를 다루는 머신러닝 파이프라인은 Apache에서 나온 Airflow, 쿠버네티스 기반의 플랫폼인 Kubeflow, 오픈소스 플랫폼인 MLflow가 있습니다. 이러한 오픈소스 플랫폼들보다 TFX가 갖고 있는 장점이 어떤 것이 있을까요?\n",
    "\n",
    "#### TFX의 장점\n",
    "[MLOps의 대표적인 툴들 (mlflow, airflow, Kubeflow)]\n",
    "\n",
    "TFX가 다른 오픈소스 플랫폼들보다 좋은 이유로는 TFX 단일 오픈소스 플랫폼로 End-to-End로 구현가능하다는 점입니다. Airflow는 범용적인 목적을 가진 task orchestration만을 지원하지만 Kubeflow는 머신러닝에서의 workflow orchestration과 Model management, notebook workspace까지 지원합니다. 그렇지만 Kubeflow는 Kubernetes를 구동해야 하기 때문에 리소스를 많이 먹는 편입니다. MLflow의 경우 간단하게 사용할 수 있고 Jupyter Notebook까지 지원합니다. 그러나 MLflow에는 하이퍼파라미터 튜닝을 지원하지 않는 단점을 갖고 있습니다.  \n",
    "\n",
    "[TensorFlow Extended]\n",
    "한편 TFX는 컴포넌트로 관리하기 때문에 다양한 환경에서 사용할 수 있게 만들었습니다. CSV뿐만 아니라 BigQuery를 활용할 수도 있으며 Kubeflow pipeline으로 커스터마이징도 가능합니다. 뿐만 아니라 Google Cloud와의 연계도 뛰어나 Vertex AI를 활용하면 TFX 적용이 상당히 쉽습니다. 뿐만 아니라 TFX는 CPU/GPU같은 환경에 상관없이 사용가능합니다.  \n",
    "\n",
    "그러나.. TFX라고 장점만을 갖고 있는 것은 아닙니다. 컴포넌트 단위로 관리하기 때문에 파이프라인이 복잡해지면 설정 값의 의미가 퇴색되기도 하고 설정값이 어떤 컴포넌트에 영향을 주는지 알 수 없는 상황이 오기도 합니다. 또한 TFX의 경우 2021년 7월 23일에 1.0버전이 나와 다른 플랫폼과 비교했을 때 상당히 늦게 나왔습니다. 그럼에도 강력한 성능을 갖고 있으며 우리나라 회사에서는 당근마켓과 스캐터랩이 도입해서 사용하고 있습니다.  \n",
    "\n",
    "스캐터랩 - TFX 머신러닝 파이프라인 사용하기\n",
    "- https://tech.scatterlab.co.kr/use-tfx-pipeline-with-customization/\n",
    "당근마켓 - TFX와 함께 머신러닝 파이프라인 개발하기\n",
    "- https://medium.com/daangn/tfx%EC%99%80-%ED%95%A8%EA%BB%98-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-4578f030a9c1\n",
    "\n",
    "#### TFX의 구성요소 - 컴포넌트\n",
    "TFX는 위에서 설명했던 것처럼 컴포넌트들로 구성되어 있습니다. 컴포넌트는 표준 컴포넌트와 커스터마이징이 된 컴포넌트로 구성되어 있습니다. 우리가 살펴볼 컴포넌트는 표준 컴포넌트들로 TFX에서 자주 사용될 뿐만 아니라 가장 중요한 뼈대입니다.\n",
    "\n",
    "#### ExampleGen\n",
    "\n",
    "ExampleGen TFX pipeline 컴포넌트는 데이터를 TFX Pipeline으로 넣는 컴포넌트입니다. 해당 컴포넌트는 CSV파일이나 TFRecord 혹은 BigQuery와 같은 외부 데이터 소스로 받고 출력은 tf.Example Record와 tf.SequenceExample records 혹은 .proto파일(proto buffer는 Google에서 개발한 데이터 직렬화 구조입니다. 자세한 내용은 여기를 참고해주세요!)로 나오게 됩니다.  \n",
    "\n",
    "ExampleGen은 데이터를 SchmaGen, StatisticsGen, Example Validat와 같은 TensorFlow Data Validation 라이브러리에서 사용하는 컴포넌트들로 데이터를 제공합니다. 또한 TensorFlow Transform library에서 사용하는 Transform에도 데이터를 제공하는 역할까지 하며 inference하는 동안에 대상을 배포할때도 사용합니다.  \n",
    "\n",
    "content img\n",
    "[ExampleGen 예시]  \n",
    "\n",
    "#### StatisticsGen, SchemaGen, ExampleValidator\n",
    "\n",
    "StatisticsGen은 이전에 만들었던 ExampleGen 컴포넌트 출력을 입력으로 수락한 다음 통계를 생성하는 컴포넌트입니다. 해당 컴포넌트의 경우 대화형 콘텍스트에서 출력한 다음 시각화 또한 가능합니다.  \n",
    "\n",
    "[StatisticsGen 예시]\n",
    "DB내에 어떤 구조로 데이터의 개체, 속성, 관계 등을 고려하여 데이터가 저장되는가를 나타내는 데이터베이스의 논리적인 구조를 스키마라고 합니다. SchemaGen은 스키마가 없을 경우 스키마를 생성하는 컴포넌트입니다. 해당 컴포넌트를 실행하면 스키마를 검토한 후 사용할 수 있습니다  \n",
    "\n",
    "ExampleValidator는 훈련 및 제공 데이터에 있는 문제점을 식별하는 컴포넌트입니다. ExampleValidator는 StatisticsGen 컴포넌트에 의해 계산된 데이터 통계를 Schema와 비교해서 예제 데이터에서 문제를 뽑아낼 수 있습니다.  \n",
    "\n",
    "#### Transform\n",
    "\n",
    "Transform 컴포넌트는 흔히 텐서플로 변환(TensorFlow Transform)이라고 불리며 데이터 전처리단계로 텐서플로우 그래프를 구성할 수 있습니다. TensorFlow Transform은 위에서 생성된 데이터 스키마를 사용해 파이프라인에 수집된 데이터를 전처리하며 결과물을 전처리 그래프로 시각화할 수 있게 출력하거나 머신러닝 모델을 내보낼 때 사용합니다. 또한 파이프라인의 Trainer 컴포넌트에서도 사용할 수 있게 변환합니다. Transform은 자연어처리에서의 ngram,bag of words, TFIDF등에 적용가능하며 컴퓨터 비전에서는 이미지를 디코딩하며 픽셀까지 조정가능합니다.  \n",
    "\n",
    "TensorFlow Transform은 단독으로도 사용할 수 있지만 Apache Beam에 이식해서 사용할 수 있습니다. Apache Beam은 배치 및 스트리밍 데이터 처리 파이프라인을 정의하고 실행하는 오픈 소스 통합 프로그래밍 모델입니다. 빔에 이식해서 사용할 경우 생산 환경에 모델을 더 쉽게 배포할 수 있고 Apache Beam을 메인으로 사용하고 TensorFlow Transform을 서브로 사용해 더 쉽게 관리할 수 있습니다.  \n",
    "\n",
    "#### Trainer\n",
    "\n",
    "Trainer는 TensorFlow로 모델을 작성하고 모델학습 코드를 만들고 해당 코드를 TFX에 통합시켜 파이프라인의 학습 단계를 처리하는 컴포넌트입니다. Trainer 컴포넌트를 학습하려면 컴파일된 Keras 모델이 필요하기 때문에 Trainer컴포넌트가 작동하는 함수에는 반드시 케라스 모델이 있어야 합니다. Trainer 컴포넌트에서 모델 학습 API에서 fit 메소드를 사용해야 합니다. 이 함수들을 기반으로 Trainer 컴포넌트가 실행되면 savedModel을 사용해서 모델을 저장할 수 있습니다. 또한 Trainer 컴포넌트에 텐서보드를 연결해 모델의 프로파일을 생성해 성능 병목 현상이 파악가능합니다.  \n",
    "\n",
    "#### Tuner\n",
    "\n",
    "TFX의 Tuner는 Keras에서 사용하는 KerasTuner와 Google Cloud Platform에서 제공하는 Tuner를 사용할 수 있습니다. KerasTuner의 경우 코드로 제어할 수 있어 쉽게 하이퍼파라미터 튜닝을 할 수 있으며 병렬 튜닝도 지원해 효율성도 보장됩니다. 또한 KerasTuner에는 Oracle이라는 알고리즘으로 튜닝을 진행하는데 기본적으로 많이 사용되는 Grid Search나 Random Search뿐만 아니라 Bayesian Optimization도 지원해 하이퍼파라미터의 잠재적 최적값을 구할 수 있습니다. Google Cloud Platform에서 제공하는 CloudTuner는 KerasTuner에서 사용하는 알고리즘을 전부 사용가능하지만 클라우드 비용이 발생하는 단점을 갖고 있어 TFX에서의 Tuner는 대부분 KerasTuner를 사용합니다.  \n",
    "\n",
    "#### Evaluator, Pusher\n",
    "\n",
    "Evaluator 컴포넌트는 TensorFlow Model Analysis라는 라이브러리를 활용해 검증 데이터셋 에 대한 모델 예측을 평가합니다. TensorFlow Model Analysis는 Trainer 컴포넌트가 내보낸 모델을 기반으로 지표를 계산하는 라이브러리입니다. 텐서보드의 경우 모델 학습 중 미니배치상에 추론된 대략적인 지표만 제공하지만 해당 라이브러리는 전체 평가 데이터셋에 거쳐 지표를 계산합니다. Evaluator 컴포넌트는 TFX에서 TFMA를 구현하기 위해 사용하는 것입니다.  \n",
    "\n",
    "한편 Pusher 컴포넌트는 Evaluator 컴포넌트가 모델을 승인했는지 확인하고 승인받았다면 모델을 서빙 파일 경로로 밀어넣는 컴포넌트입니다. Pusher를 진행하게 된다면 텐서플로 서빙에서 모델을 선택할 수 있게 됩니다.  \n",
    "\n",
    "#### TensorFlow Serving\n",
    "\n",
    "TensorFlow Serving은 텐서플로우 그래프를 배포할 수 있으며 표준화된 엔드포인트로 그래프에서 예측할 수 있게 하는 라이브러리입니다. TensorFlow Serving은 모델 및 버전 관리를 처리하고 정책 기반으로 모델을 서비스하고 다양한 소스에서 모델을 로드할 수 있습니다. TensorFlow Serving은 저장된 모델에 대한 REST API추론 서버를 만들어내서 결과값을 반환합니다.  \n",
    "\n",
    "#### 그렇다면 이번 노드에서 공부할 내용은?\n",
    "TFX는 다양한 컴포넌트들이 존재하며 이를 공부하기 위해서는 많은 시간이 소요됩니다. 이번 노드에서는 우리가 바로 사용할 수 있는 동시에 매우 쉽게 사용할 수 있는 컴포넌트 2개를 사용할 예정입니다. 바로 KerasTuner와 TensorFlow Serving입니다.  \n",
    "\n",
    "KerasTuner를 통해서 여러분들이 Keras로 모델을 만들었을때 하이퍼파라미터 튜닝을 쉽게 할 수 있도록 도와줄겁니다. 또한 TensorFlow Serving은 모델을 REST API추론 서버를 만들게 됨으로써 어플리케이션화시킬 수도 있다고 생각합니다. 그렇다면 재미있는 KerasTuner와 TensorFlow Serving의 세계에 빠져볼까요?  \n",
    "\n",
    "-----\n",
    "\n",
    "### 13-5  AI도 데이터 중심으로! - Data Centric AI\n",
    "지금까지 우리가 공부한 내용을 요약하면 다음과 같이 이야기할 수 있습니다.  \n",
    "- 모델을 단순히 만드는 것에서 그치는 것이 아닌 실제 서비스에 적용하려면 다양한 장벽들이 존재한다.\n",
    "- 머신러닝 시스템의 구성요소에는 데이터 수집부터 모니터링까지 다양하게 존재한다.\n",
    "\n",
    "그렇다면 이정도 내용만 안다면 우리는 산업에서 다양한 머신러닝 모델을 사용하는 엔지니어가 될 수 있을까요? 이 질문에 대한 답을 하자면 반은 맞고 반은 틀렸다고 볼 수 있습니다. 실제 머신러닝 엔지니어들은 데이터 수집부터 시작해 배포를 하고 마지막으로 모니터링을 합니다. 그런데 여기서 가장 많은 시간을 쏟는 스텝은 어디일까요?  \n",
    "\n",
    "\n",
    "#### 머신러닝 엔지니어의 현실\n",
    "머신러닝 엔지니어들은 실제 머신러닝을 적용하려고 할때 가장 먼저 맞닥뜨리는 난관은 다름아닌 \"현실의 데이터가 생각보다 너무 더럽다\"라고 이야기합니다. 밑의 그림은 우리가 공부하면서 사용하는 데이터 (iris, Titanic, Cancer Data)와 실제 데이터가 얼마나 차이가 나는지를 보여주는 밈입니다.\n",
    "\n",
    "- https://www.youtube.com/watch?v=PzcvhHWN7h0\n",
    "\n",
    "\n",
    "#### 한발 더 나아간 방법론 - Data Centric AI\n",
    "2021년, 앤드류 응 교수님은 기존의 머신러닝 방법론을 넘어선 'Data Centric AI'라는 새로운 개념을 제시했습니다. 기존의 머신러닝은 주어진 데이터 세트에 적합한 효과적인 모델을 만드는 데 중점을 두었습니다. 그러나 실제 중요한 데이터를 다룰 때, 데이터가 복잡하고 더러운 경우가 많아 모델 개선만으로 성능 향상을 기대하기 어렵습니다. Data Centric AI는 데이터 집합 자체를 고정된 것이 아니라 개선할 수 있는 대상으로 보고 접근해서 개선하는 새로운 분야입니다. 기존에는 데이터 과학자들이 주로 시행착오와 직관에 의존하여 수동적으로 이러한 작업을 해왔지만, Data Centric AI는 데이터 개선 작업을 체계적인 엔지니어링 분야로 간주하고 있습니다.  \n",
    "\n",
    "- https://www.youtube.com/watch?v=06-AZXmwHjo\n",
    "\n",
    "\n",
    "Google, Meta, OpenAI등 많은 AI기업들이 모델 위주의 AI개발와 더불어 Data Centric AI를 도입하고 있습니다. 국내에서는 Superb AI, 셀렉트스타 등 데이터셋 구축 회사들부터 업스테이지, 마키나락스 등의 AI 솔루션 회사들까지 Data Centric AI를 도입하고 있습니다. 특히 업스테이지의 경우 LLM팀 내부에 Data Centric AI부서를 두어서 관리하고 있으며 양질의 데이터셋을 유지하기 위해 많은 노력을 하고 있습니다.\n",
    "\n",
    "업스테이지 Data Centric AI 1편- Data-Centric AI와 Real-World\n",
    "- https://www.upstage.ai/blog/tech/data-centric-ai-in-the-real-world\n",
    "업스테이지 Data Centric AI 2편- DMOps(Data Management Operation and Recipes), 현업에서 데이터 구축하기\n",
    "- https://www.content.upstage.ai/blog/tech/dmops-data-management-operation-and-recipes\n",
    "업스테이지 Data Centric AI 3편- Data-Centric AI 관점으로 재해석하는 자연언어처리 기반 History of AI\n",
    "- https://www.upstage.ai/blog/tech/reinterpreting-the-history-of-nlp-based-ai-through-a-data-centric-perspective\n",
    "Superb AI Data Centric AI 영상\n",
    "- https://www.youtube.com/watch?v=o2Z8T0D5f3I\n",
    "Google Cloud & Snorkel AI가 협업해서 만든 Data Centric AI\n",
    "- https://cloud.google.com/blog/products/data-analytics/how-accelerate-data-centric-ai-development-google-cloud-and-snorkel-ai?hl=en\n",
    "\n",
    "#### Data Centric AI 분야\n",
    "Data Centric AI는 데이터의 질과 구조에 중점을 두는 인공지능 개발 방법론이기 때문에 이 분야에서는 모델의 성능을 향상시키기 위해 데이터 자체를 개선하고 최적화하는 것이 핵심입니다. 그러기에 모델은 고정해 둔채로 데이터를 면밀하게 분석하고 데이터 자체 결함을 최소화시켜 성능을 좋게 만들어야 합니다. 그러기 위해서는 Label 검수하기, Confident Learning, 데이터 클리닝, 기준에 맞게 데이터셋 구축하기, Data Centric에 맞는 평가지표 만들기가 있습니다. 그럼 하나씩 알아보겠습니다. 해당 내용은 MIT에서 진행한 Introduction to Data-Centric AI에서 가져왔습니다.\n",
    "\n",
    "#### Label 검수하기\n",
    "\n",
    "Label 검수는 데이터셋의 정확도와 신뢰도를 보장하기 위해 중요한 단계입니다. 특히 이미지나 텍스트 데이터와 같은 비정형데이터를 다루는 딥러닝 엔지니어들은 데이터 크기는 살펴보지만 실제 데이터를 열어서 잘 확인하지 않습니다. 그런데 실제 데이터셋들중에서 label이 잘못된 경우가 꽤 많습니다..!! 그렇기에 데이터에 할당된 label이 정확한지 확인하고, 오류나 불일치를 수정하는 작업이 반드시 들어가야 합니다. 이 과정을 거쳐야지만 더 정확하고 신뢰할 수 있는 AI 모델을 구축할 수 있습니다.\n",
    "\n",
    "#### Confident Learning\n",
    "\n",
    "[Confident Learning을 도표로 표현한 그림]\n",
    "Confident Learning은 불확실한 라벨을 가진 데이터를 식별하고 처리하는 방법입니다. Confident Learning은 노이즈가 있는 데이터를 없애고 노이즈를 추정하기 위해 계산하고 예제에 대한 랭킹을 매기는 학습방식입니다. Confident Learning을 하게 되면 노이즈 라벨에 대한 분포를 알 수 있어 추가적인 데이터 구축할 때 유용하게 사용할 수 있으며 label 오류 또한 검출할 수 있습니다. Confident Learning은 반복학습하는 딥러닝과 달리 한번으로 학습가능하기에 효율적입니다. Confident Learning은 현재 Python 라이브러리인 cleanlab을 통해서 쉽게 할 수 있습니다.\n",
    "\n",
    "#### 데이터 전처리\n",
    "\n",
    "데이터 전처리과정은 데이터의 label 분포가 골고루 되어 있는지를 확인하는 것뿐만 아니라 한쪽으로 치우쳐진 데이터들로 모델을 학습하는 방법도 포함됩니다. 또한 데이터중에서 이상치가 있는지 탐지하거나 이상치를 처리하는 과정에 대한 내용도 데이터 전처리에 포함됩니다. 위에서 이야기한 내용들은 대부분 머신러닝에서도 사용하는 기법이지만 Data Centric AI관점에서는 데이터가 변하는것까지 확인해야 합니다. Data Centric AI를 실현하기 위해서는 서비스에서 쓰인 데이터가 다시 훈련 데이터로 들어가는 과정까지 설계해야 합니다. 문제는 서비스의 경우 시간 그리고 트렌드에 따라 사람들이 사용하는 데이터가 달라질 가능성이 있습니다. 이런 오차를 줄이는 역할도 Data Centric AI에서는 전처리단에 속한다고 볼 수 있습니다.\n",
    "\n",
    "#### 데이터셋 구축하기\n",
    "\n",
    "content img\n",
    "[데이터셋 구축할 때 자주 사용하는 Multi Annotator 기법]\n",
    "효과적인 AI 모델을 위해서는 고품질의 데이터셋이 필수적입니다. 데이터셋 구축 과정에서는 관련 데이터를 수집, 정리, 라벨링하는 작업이 포함됩니다. AI에는 엄청난 수의 데이터를 수집해야 하기 때문에 필연적으로 엔지니어 혼자서 하는 방법보다 다른 사람들과의 협업을 통해 구축할수 밖에 없습니다. 다른 사람들과 협업을 하게 되었을때 데이터를 판단하는 기준이 제각기 달라질 수 있으며 라벨링 또한 주관적 판단으로 인해 라벨링의 일관성이 무너질 수 있습니다. Data Centric AI에서는 데이터셋 구축에 대한 기준점을 만드는것부터 일정부분 모델을 만들어서 자동화하는 것까지 다양한 솔루션을 이야기합니다.\n",
    "\n",
    "#### Data Centric에 특화된 평가\n",
    "\n",
    "우리가 기존의 AI에서 평가하는 지표들을 Data Centric AI에서도 마찬가지로 봐야 합니다. 다만 Data Centric AI에서는 데이터 질을 중심으로 모델을 평가해야 하기 때문에 데이터셋에 대한 평가도 진행해야 합니다. 데이터셋을 평가하는 방식으로는 데이터의 학습 결과를 맞다/틀리다 로 나누는 것이 아닌 확률적으로 만들어 모델이 훈련 데이터 결과에 \"얼만큼\" 틀렸는지 확인하는 수단이 대표적입니다. 이러한 Data Centric에 특화된 평가를 도입하면 데이터셋의 문제점을 발견하고 개선하여, 최종적으로 AI 모델의 성능을 높일 수 있습니다.\n",
    "\n",
    "#### 결론\n",
    "Data Centric AI는 서비스와 연결해서 사용했을 때 큰 효과를 발휘한다고 생각합니다. 특히 데이터셋을 구축하거나 Data Centric AI에 특화된 평가와 같은 경우가 그렇다고 생각합니다. 다만 Data Centric AI관점은 우리가 데이터를 바라볼 때 큰 시사점을 줍니다. 이전 scikit-learn을 활용하는 태스크의 경우 우리는 어떤 방식으로 접근했나요? 그때의 경우 우리 모두 데이터셋을 확인하고 전처리를 거친 다음 피쳐 엔지니어링을 한 다음 모델에 넣고 결과를 도출했습니다. 그런데 딥러닝에서는 우리 모두 데이터를 받아온 다음 크기만 확인하고 모델에 넣고 더 좋은 결과를 얻기 위한 실험을 진행했습니다. Data Centric AI는 딥러닝에서도 데이터를 직접 확인하고 label이 제대로 붙어있는지 확인하는 작업이 필요하다라는 것을 시사한다고 생각합니다. 이후 프로젝트에서는 이런 과정을 한번 거칠 예정입니다!\n",
    "\n",
    "### 13-6. 모델을 더 완벽하게 만드는 방법 : KerasTuner\n",
    "[Keras-Tuner 소개]\n",
    "우리가 볼 첫번째 MLOps는 하이퍼파라미터 튜닝입니다. 그중에서 우리가 사용할 툴은 KerasTuner입니다.  \n",
    "\n",
    "KerasTuner는 Keras뿐만 아니라 scikit-learn과 같은 모델에서도 커스터마이징해서 사용할 수 있는 툴이며 하이퍼파라미터 튜닝을 자동으로 할 수 있게 도와줍니다.  \n",
    "\n",
    "기존 모델에서 하이퍼파라미터 튜닝을 진행한다고 했을 때 딥러닝의 경우 일일이 바꿔가면서 함수를 만들고 정리했습니다. 그러나 KerasTuenr를 사용하고 범위를 결정하는 함수를 잘 선택한다면 하이퍼파라미터 튜닝을 원하는대로 할 수 있습니다.  \n",
    "\n",
    "그렇다면 KerasTuner를 사용하러 떠나볼까요?  \n",
    "\n",
    "이번 실습은 MNIST로 간단하게 할 수 있는 하이퍼파라미터 튜닝작업입니다!  \n",
    "\n",
    "우선 디렉토리 먼저 만들어놓도록 하겠습니다.  \n",
    "\n",
    "이번 실습에 앞서 우선 KerasTuner를 설치하겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/aiffel/mlops\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05789189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN을 사용할 예정이라 차원 수를 하나 더 추가해줍니다.\n",
    "# 또한 label을 categorical을 활용해 변환합니다.\n",
    "X_train = x_train.reshape(-1,28, 28, 1) \n",
    "X_test = x_test.reshape(-1,28,28,1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-learn에 내장되어 있는 train_test_split으로 train data와 validation data를 나누어줍니다.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40572241",
   "metadata": {},
   "source": [
    "이번에는 제가 짠 DeepTuner를 살펴보겠습니다!  \n",
    "\n",
    "DeepTuner의 경우 kerastuner.Tuner를 인자로 하는 class이며 class에서 수행하는 함수는 run_trial, save_model load_model입니다.  \n",
    "\n",
    "run_trial 함수에서 제일 중요한 부분은 hypermodel과 trial입니다.  \n",
    "\n",
    "KerasTuner에서의 hypermodel은 모델을 공유 및 재사용하기 위해 검색 공간을 캡슐화하는 모델입니다. hypermodel의 경우 hp라는 인수를 활용해서 keras.Model을 생성합니다.  \n",
    "즉 hypermodel은 우리가 만들고 싶은 모델을 쌓는 과정을 거치는데 이때 하이퍼파라미터 튜닝에 대한 검색공간을 만들어줄때 hp라는 인수를 사용해서 만든 모델입니다.  \n",
    "hypermodel의 경우 build 메소드를 활용하면 모델이 빌드가 되면서 하이퍼파라미터 튜닝이 시작합니다.  \n",
    "\n",
    "trial의 경우에는 Oracle에 속하는 class입니다.  \n",
    "Oracle이란 KerasTuner의 모든 검색 알고리즘에서 사용하는 기본 클래스이며 크게 RandomSearchOracle, BayesianOptimizationOracle, HyperbandOracle이 있습니다.  \n",
    "쉽게 설명하면 Oracle은 KerasTuner가 하이퍼파라미터를 정할 때 사용하는 알고리즘이라고 생각하시면 됩니다!  \n",
    "여기서 trial.hyperparameter는 Oracle이 찾아야 하는 하이퍼파라미터입니다. 즉 hypermodel에서의 hp입니다.  \n",
    "제가 model.fit()을 할때 batch_size도 고를 수 있게 만들었습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X, y, validation_data, **fit_kwargs):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        model.fit(X, y, batch_size=trial.hyperparameters.Choice(\n",
    "            'batch_size', [16, 32]), **fit_kwargs)\n",
    "\n",
    "\n",
    "        X_val, y_val = validation_data\n",
    "        eval_scores = model.evaluate(X_val, y_val)\n",
    "        return {name: value for name, value in zip(\n",
    "            model.metrics_names,\n",
    "            eval_scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c05ca9",
   "metadata": {},
   "source": [
    "이번에는 build_model쪽을 보도록 하겠습니다.  \n",
    "\n",
    "build_model은 위에서 설명한것처럼 hypermodel을 만들어줘야 합니다. 제가 만든 hypermodel은 총 2가지 기법이 들어가 있으며 주의사항도 1가지 있습니다.  \n",
    "\n",
    "우선 주의사항부터 말씀드리면 해당 모델의 경우 hypermodel이기 때문에 Input지정이 필수입니다!  \n",
    "그렇기에 여러분들이 넣고 싶은 모델에 대한 shape을 꼭 기재해주셔야 합니다!  \n",
    "\n",
    "제가 사용한 첫번째 기법은 바로 layer의 숫자도 KerasTuner에게 맡겼습니다.  \n",
    "for문을 확인해보겠습니다  \n",
    "\n",
    "첫번째 for문의 경우 hp.Int로 만들어 검색공간은 정수로 만들고 가장 작은값을 1로 가장 큰값을 10으로 두었습니다.  \n",
    "이렇게 설정하면 최소 1개에서 최소 10개의 layer를 쌓을 수 있게 설정할 수 있습니다.  \n",
    "\n",
    "제가 쌓고싶은 layer는 conv2D인데 kernel_size는 (3,3)이며 차원수는 최소 32에서 최대 256으로 바꾸었습니다.  \n",
    "\n",
    "두번째 for문을 살펴보겠습니다. 두번째 for문도 최소 1개에서 3개로 설정했지만 Dense Layer의 경우 나올 수 있는 차원을 32,64,128,256중 1개를 선택하도록 만들었습니다.  \n",
    "\n",
    "이러한 방식으로 hypermodel을 만들면 하고싶은 하이퍼 파라미터 튜닝을 진행할 수 있습니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape = X_train.shape[1:], name = 'inputs'))\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
    "              model.add(tf.keras.layers.Conv2D(hp.Int(\n",
    "                  'units_{i}'.format(i=i), min_value=32, max_value=128, step=5), (3,3),activation='relu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for i in range(hp.Int('n_connections', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Choice(f'n_nodes',\n",
    "                                  values=[32,64,128, 256]), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name = 'outputs'))\n",
    "    model.compile(optimizer = 'adam',loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5001b71",
   "metadata": {},
   "source": [
    "마지막으로 keras_tuner를 정의하고 탐색하는것까지 보도록 하겠습니다.\n",
    "\n",
    "저는 이번 모델의 경우 BayesianOptimizationOracle을 사용할 예정이며 목표는 accuracy와 max로 둘 예정입니다. 실제 trial은 10번으로 지정할 것입니다.\n",
    "\n",
    "hypermodel은 build_model을 넣어주시고 project이름도 작성해주세요.\n",
    "\n",
    "마지막으로 search함수에 X_train, Y_train, validation data, epoch을 넣고 탐색합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00af14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keras_tuner = DeepTuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('accuracy', 'max'),\n",
    "        max_trials=10,\n",
    "        seed=42),\n",
    "    hypermodel=build_model,\n",
    "    overwrite=True,\n",
    "    project_name='my_keras_tuner')\n",
    "\n",
    "# 해당 모델 학습시간은 약 10분정도 걸립니다!\n",
    "my_keras_tuner.search(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2da4b0",
   "metadata": {},
   "source": [
    "가장 좋은 모델을 뽑는 방법은 KerasTuner.get_best_hyperparamters를 이용해서 가장 좋은 하이퍼파라미터를 뽑아내는 작업입니다  \n",
    "하이퍼파라미터를 뽑았으면 build_model()에 집어넣어 가장 좋은 모델을 선언합니다.  \n",
    "\n",
    "그렇다면 여러분들이 만든 가장 좋은 모델을 확인해볼까요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = my_keras_tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "model = build_model(best_hps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052d1ef",
   "metadata": {},
   "source": [
    "최고의 하이퍼 파라미터만 뽑았기 때문에 아직 모델학습이 되지 않았습니다!  \n",
    "이번에 epoch을 5번정도 주어서 모델학습을 진행합니다!  \n",
    "\n",
    "만일 여러분들이 무거운 모델을 돌릴 경우 하이퍼파라미터 튜닝작업이 매우 느려질 수 있습니다.  \n",
    "그때의 경우 하이퍼파라미터 튜닝할때 epoch을 3-4정도로 작게 준 다음 최고의 하이퍼파라미터를 뽑아낸 다음\n",
    "본격적인 모델학습때 epoch을 넉넉하게 주는 것도 방법입니다!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f555b4",
   "metadata": {},
   "source": [
    "이제 모델을 저장할 차례입니다.  \n",
    "\n",
    "우리가 이전까지 자주 사용한 저장방법은 HDF5파일 (.h5)로 저장하는 방법이었습니다.  \n",
    "\n",
    "HDF파일로 저장하는 방식은 이전 Keras에서 모델을 저장하는 방식이었으나 사실 이 방법은 TensorFlow나 Keras에서 그다지 선호하지 않는 저장방식입니다.  \n",
    "\n",
    "TensorFlow의 경우 공식적으로 지원하는 모델 저장방식은 SavedModel입니다.  \n",
    "\n",
    "[SavedModel 파일구조]\n",
    "SavedModel은 .h5파일처럼 모델의 가중치와 모델을 전부 하나의 파일로 관리하는 방식이 아닌 모델, 가중치를 따로 구분해서 저장하는 방식입니다.  \n",
    "\n",
    "SavedModel은 크게 3가지로 구성되어 있습니다.  \n",
    "\n",
    "- saved_model.pb : pb는 프로토콜 버퍼를 의미하며 해당 파일은 내보낸 모델 그래프 구조를 포함하고 있습니다.\n",
    "- variables : 내보낸 변수값이 있는 이진 파일과 내보낸 모델 그래프에 해당하는 체크포인트를 포함하고 있습니다\n",
    "- assets : 내보낸 모델을 불러올 때 추가적인 파일이 필요한 경우 이 폴더에 파일이 생성됩니다.\n",
    "이 방식으로 진행한다면 모델을 배포할 때 유리합니다.\n",
    "\n",
    "Keras의 경우 .keras파일을 선호합니다. .keras파일은 .h5파일과 마찬가지로 가중치와 모델을 전부 하나의 파일로 관리합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getenv('HOME') + '/aiffel/mlops/best_model/1'\n",
    "fname = os.path.join(save_path, 'model')\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f2805",
   "metadata": {},
   "source": [
    "### 13-7. 이제는 모델을 배포할 차례! : TFServing & TFLite\n",
    "content img\n",
    "[GitHub에 있는 TFServing 설명]\n",
    "모델을 만들었다면 이제는 배포를 진행해봐야죠!    \n",
    "\n",
    "배포를 진행하는 방법은 크게 2가지로 나눌 수 있습니다.  \n",
    "\n",
    "- 클라우드를 활용해서 모델을 배포하는 방식\n",
    "- 경량화된 모델을 만들어서 휴대폰같은 디바이스에서도 모델이 실행되게 만드는 방식\n",
    "TensorFlow는 첫번째 방식을 TFServing을 통해서 가능하게 만들며 2번째 방식은 TFLite방식으로 가능하게 만듭니다.  \n",
    "그렇다면 2개를 더 자세하게 알아볼까요?  \n",
    "\n",
    "#### TFServing\n",
    "TFServing이란 텐서플로우 그래프를 배포할 수 있으며 표준화된 엔드포인트를 제공합니다. 또한 모델 및 버전관리가 가능하며 정책 기반으로 모델을 서비스할 수 있습니다.  \n",
    "또한 지연 시간이 최대한 짧게 만드는 고성능 처리량에서도 초점을 맞추고 있습니다.  \n",
    "\n",
    "TFServing을 하는 방식은 크게 2가지가 있습니다.  \n",
    "\n",
    "- Docker를 활용한 배포\n",
    "- 우분투 터미널을 활용한 배포\n",
    "이번에 2개 모두 설명할 예정입니다.\n",
    "\n",
    "#### 주의사항 \n",
    "우분투 터미널 실습의 경우 실제 결과물이 나오려면 로컬에서 진행해야 합니다.  \n",
    "LMS에서 실행되지 않는 이유는 LMS 시스템에 들어가 있는 GPU클라우드도 Docker Image이며 쿠버네티스로 관리되고 있습니다.  \n",
    "그렇기에 WSL2와 Docker 환경세팅을 해주세요..!!  \n",
    "\n",
    "WSL2 설치 + 윈도우에서 Docker 설치하기\n",
    "- https://axce.tistory.com/121\n",
    "파일을 우분투 디렉토리로 옮기는 방법\n",
    "- https://bbeomgeun.tistory.com/139\n",
    "macOS에서 Docker 설치하기\n",
    "- https://kplog.tistory.com/288\n",
    "\n",
    "#### TFServing 우분투 터미널로 실습하기\n",
    "우선 우분투 터미널 실습부터 진행하겠습니다!\n",
    "\n",
    "클라우드 쉘을 열고 해당 스크립트를 넣어주세요!\n",
    "\n",
    "$ echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "$ sudo apt update\n",
    "$ sudo apt install tensorflow-model-server\n",
    "해당 스크립트는 우분투에 tensorflow-model-server를 설치해 배포용 텐서플로우 서버를 구축하는 것입니다!\n",
    "\n",
    "그 다음 스크립트는 모델을 배포하는 스크립트입니다.\n",
    "\n",
    "$ tensorflow_model_server --port=8500 \\\n",
    "\t\t\t\t\t\t --rest_api_port=8501 \\\n",
    "\t\t\t\t\t\t --model_name=my_model \\\n",
    "\t\t\t\t\t\t --model_base_path=/aiffel/mlops/best_model/model \n",
    "여기서 model_base_path는 실제 SavedModel을 넣은 디렉토리로 바꿔주세요! (주의사항) SavedModel을 넣을 때 model 디렉토리 내부에 숫자 '1' 폴더를 만들고 넣어주세요!\n",
    "\n",
    "TFServing Docker로 실습하기\n",
    "Docker를 설치하셨다면\n",
    "\n",
    "docker pull tensorflow/serving\n",
    "을 WSL2 쉘에 실행시켜주세요 (맥북은 터미널에서도 가능합니다!)\n",
    "\n",
    "docker run -p 8500:8500 \\\n",
    "\t\t\t-p 8501:8501 \\\n",
    "\t\t\t--mount type=bind,source=/tmp/models,target=/models/my_model\n",
    "\t\t\t-e MODEL_NAME=my_model \\\n",
    "\t\t\t-e MODEL_BASE_PATH=/models/my_model \\\n",
    "\t\t\t-t tensorflow/serving\n",
    "그 다음 도커를 지정해주고 실행시켜 주세요\n",
    "\n",
    "해당 명령어의 경우 첫번째 줄은 기본 포트를 지정하는 것이며 2번째줄은 API 포트를 의미합니다. 3번째 줄은 모델 티렉토리를 마운트하는 것입니다. 4번째 줄은 모델 이름을 지정해주고 5번째 줄은 모델의 기본 경로를 의미합니다. 마지막 줄은 tensorflow/serving을 사용한다는 뜻입니다!\n",
    "\n",
    "만약 배포에 성공했다면 다음과 같은 그림이 나옵니다!\n",
    "\n",
    "content img\n",
    "[TFServing 결과물]\n",
    "content img\n",
    "[TFLite 로고]\n",
    "TFLite로 경량화 모델 만들기\n",
    "TFLite는 TensorFlow로 만들어진 모델을 휴대폰같은 기기에서도 실행될수 있게 더 작은 모델 크기로 변환해서 배포하는데 사용하게 만드는 방법입니다.\n",
    "TFLite의 경우 양자화라는 기법을 활용해 모델의 크기를 줄이지만 그렇다고 해서 모델의 성능이 크게 저하되지 않습니다.\\\n",
    "\n",
    "TFLite의 경우 TensorFlow에 내장되어 있어 별도의 설치가 없이 작동하는 방식입니다!\n",
    "\n",
    "그렇다면 tflite파일을 만들어보도록 하겠습니다! 첫번째로 아까 만들었던 모델을 불러옵니다!\n",
    "\n",
    "주의사항 현재 LMS에서 tflite모델이 만들어지긴 하지만 원인을 모르겠으나 모바일에서 tflite파일을 구동할때 중요한 '서명'이 지워진 상태로 나오고 있습니다. 그렇기에 실제 프로젝트를 진행할 때는 LMS에서 tflite파일을 만들기보다 Google Colab에서 만드는 것을 추천합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
